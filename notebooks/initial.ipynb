{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, GlobalAveragePooling2D, LSTM, TimeDistributed, Dropout, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "from data import Data\n",
    "from metrics import SlicewiseAccuracy\n",
    "from data_generator import PhaseDataGenerator, SliceDataGenerator\n",
    "from results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_app = tf.keras.applications.mobilenet\n",
    "keras_model = tf.keras.applications.mobilenet.MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializer Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=keras_app.preprocess_input)\n",
    "phase_gen = PhaseDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=2,\n",
    "                               shuffle=True, image_data_generator=datagen)\n",
    "slice_gen = SliceDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=32,\n",
    "                               shuffle=True, image_data_generator=datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_gen.get_slice_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.isclose(slice_gen[0][0][0].min(), -1, rtol=1.0e-4))\n",
    "assert(np.isclose(slice_gen[0][0][0].max(), 1, rtol=1.0e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.isclose(phase_gen[0][0][0].min(), -1, rtol=1.0e-4))\n",
    "assert(np.isclose(phase_gen[0][0][0].max(), 1, rtol=1.0e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = keras_model(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3))\n",
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Slice Extraction\n",
    "Skip this part for end-to-end model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractors\n",
    "cnn_ext = backbone\n",
    "rnn_ext = Sequential()\n",
    "rnn_ext.add(TimeDistributed(backbone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_cnn = cnn_ext.predict(slice_test_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_rnn = rnn_ext.predict(phase_test_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn = np.ndarray((0, 5))\n",
    "for _, labels in tqdm(slice_test_gen):\n",
    "    y_cnn = np.concatenate([y_cnn, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rnn = np.ndarray((0, 25, 5))\n",
    "for _, labels in tqdm(phase_test_gen):\n",
    "    y_rnn = np.concatenate([y_rnn, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data.data[\"KAG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = np.array(list(patients.keys()))\n",
    "slices_by_patient = defaultdict(int)\n",
    "slice_ids_by_patient = dict()\n",
    "phase_ids_by_patient = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pids, test_pids = train_test_split(patient_ids, train_size=0.8, random_state=0)\n",
    "train_pids.sort()\n",
    "test_pids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "for i, (patient, phases) in enumerate(sorted(list(patients.items()))):\n",
    "    phases = list(phases.values())\n",
    "    n_slices = len(phases[0])\n",
    "    slices_by_patient[patient] = n_slices\n",
    "    slice_ids = list(range(current, current + n_slices * 2))\n",
    "    slice_ids_by_patient[patient] = slice_ids\n",
    "    phase_ids_by_patient[patient] = [i * 2, i * 2 + 1]\n",
    "    current = current + n_slices * 2\n",
    "    assert(len(phases[0]) == len(phases[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_train_sids = []\n",
    "slice_test_sids = []\n",
    "for pid in train_pids:\n",
    "    slice_train_sids.extend(slice_ids_by_patient[pid])\n",
    "for pid in test_pids:\n",
    "    slice_test_sids.extend(slice_ids_by_patient[pid])\n",
    "    \n",
    "phase_train_sids = []\n",
    "phase_test_sids = []\n",
    "for pid in train_pids:\n",
    "    phase_train_sids.extend(phase_ids_by_patient[pid])\n",
    "for pid in test_pids:\n",
    "    phase_test_sids.extend(phase_ids_by_patient[pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cnn_train = x_cnn[slice_train_sids]\n",
    "x_cnn_test = x_cnn[slice_test_sids]\n",
    "y_cnn_train = y_cnn[slice_train_sids]\n",
    "y_cnn_test = y_cnn[slice_test_sids]\n",
    "\n",
    "x_rnn_train = x_rnn[phase_train_sids]\n",
    "x_rnn_test = x_rnn[phase_test_sids]\n",
    "y_rnn_train = y_rnn[phase_train_sids]\n",
    "y_rnn_test = y_rnn[phase_test_sids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_top = Sequential()\n",
    "rnn_top.add(LSTM(256, input_shape=(25, 1024), return_sequences=True))\n",
    "rnn_top.add(Dropout(0.5))\n",
    "#rnn_top.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "#rnn_top.add(TimeDistributed(Dropout(0.5)))\n",
    "rnn_top.add(TimeDistributed(Dense(5, activation=\"softmax\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_top.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[SlicewiseAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = list()\n",
    "loss = list()\n",
    "vacc = list()\n",
    "vloss = list()\n",
    "for i in range(5):\n",
    "    print(\"Iteration\", i)\n",
    "    rnn_top = Sequential()\n",
    "    rnn_top.add(LSTM(256, input_shape=(25, 1024), return_sequences=True))\n",
    "    rnn_top.add(Dropout(0.5))\n",
    "    #rnn_top.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "    #rnn_top.add(TimeDistributed(Dropout(0.5)))\n",
    "    rnn_top.add(TimeDistributed(Dense(5, activation=\"softmax\")))\n",
    "    rnn_top.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=\"adam\",\n",
    "                    metrics=[SlicewiseAccuracy()])\n",
    "    history = rnn_top.fit(x_rnn_train, y_rnn_train, validation_data=(x_rnn_test, y_rnn_test),\n",
    "                          batch_size=2, epochs=100, verbose=0)\n",
    "    acc.append(np.array(history.history[\"slicewise_accuracy\"]))\n",
    "    loss.append(np.array(history.history[\"loss\"]))\n",
    "    vacc.append(np.array(history.history[\"val_slicewise_accuracy\"]))\n",
    "    vloss.append(np.array(history.history[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhistory = dict(\n",
    "    accuracy=np.stack(acc).mean(axis=0),\n",
    "    loss=np.stack(loss).mean(axis=0),\n",
    "    val_accuracy=np.stack(vacc).mean(axis=0),\n",
    "    val_loss=np.stack(vloss).mean(axis=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_top = Sequential()\n",
    "cnn_top.add(Dense(256, activation=\"relu\"))\n",
    "cnn_top.add(Dropout(0.5))\n",
    "cnn_top.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_top.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cacc = list()\n",
    "closs = list()\n",
    "cvacc = list()\n",
    "cvloss = list()\n",
    "for i in range(5):\n",
    "    print(\"Iteration\", i)\n",
    "    cnn_top = Sequential()\n",
    "    cnn_top.add(Dense(256, activation=\"relu\"))\n",
    "    cnn_top.add(Dropout(0.5))\n",
    "    cnn_top.add(Dense(5, activation=\"softmax\"))\n",
    "    cnn_top.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=\"adam\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "    history = cnn_top.fit(x_cnn_train, y_cnn_train, validation_data=(x_cnn_test, y_cnn_test),\n",
    "                          batch_size=32, epochs=100, verbose=0)\n",
    "    cacc.append(np.array(history.history[\"accuracy\"]))\n",
    "    closs.append(np.array(history.history[\"loss\"]))\n",
    "    cvacc.append(np.array(history.history[\"val_accuracy\"]))\n",
    "    cvloss.append(np.array(history.history[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chistory = dict(\n",
    "    accuracy=np.stack(cacc).mean(axis=0),\n",
    "    loss=np.stack(closs).mean(axis=0),\n",
    "    val_accuracy=np.stack(cvacc).mean(axis=0),\n",
    "    val_loss=np.stack(cvloss).mean(axis=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(10, 6))\n",
    "fig.suptitle(\"CNN=dotted, RNN=solid\")\n",
    "ax = fig.subplots()\n",
    "pd.DataFrame(rhistory).plot(ylim=[0, 1], ax=ax)\n",
    "ax.set_prop_cycle(None)\n",
    "pd.DataFrame(chistory).plot(ylim=[0, 1], ax=ax, linestyle=\"dotted\", linewidth=2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_top.evaluate(x_cnn_test, y_cnn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_top.evaluate(x_rnn_test, y_rnn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(backbone)\n",
    "cnn_model.add(Dense(256, activation=\"relu\"))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "cnn_model.layers[0].trainable = False\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_history = cnn_model.fit(slice_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(TimeDistributed(backbone))\n",
    "rnn_model.add(LSTM(256, input_shape=(25, 2048), return_sequences=True))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "#rnn_model.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "#rnn_model.add(TimeDistributed(Dropout(0.5)))\n",
    "rnn_model.add(TimeDistributed(Dense(5, activation=\"softmax\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.layers[0].trainable = False\n",
    "rnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[SlicewiseAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn_history = rnn_model.fit(phase_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=keras_app.preprocess_input)\n",
    "cnn_testgen = SliceDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=32,\n",
    "                                 shuffle=False, image_data_generator=datagen)\n",
    "rnn_testgen = PhaseDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=2,\n",
    "                                 shuffle=False, image_data_generator=datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_model.evaluate(cnn_testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn_model.evaluate(rnn_testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_preds = cnn_model.predict(cnn_testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_preds = rnn_model.predict(rnn_testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_preds.shape, rnn_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slice_index = rnn_testgen.get_slice_index()\n",
    "rnn_predictions = compile_predictions_from_phase_output(rnn_preds, slice_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slice_list = cnn_testgen.get_slice_list()\n",
    "cnn_predictions = compile_predictions_from_slice_output(cnn_preds, slice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels):\n",
    "    total_slices = 0\n",
    "    total_phases = 0\n",
    "    correct_slices = 0\n",
    "    correct_phases = 0\n",
    "\n",
    "    for phase, slices in enumerate(preds):\n",
    "        total_phases += 1\n",
    "        correct_phase = True\n",
    "        for slice, pred in enumerate(slices):\n",
    "            label = labels[phase][slice]\n",
    "            if label.sum() == 0:\n",
    "                pass\n",
    "            else:\n",
    "                total_slices += 1\n",
    "                if label.argmax() == pred.argmax():\n",
    "                    correct_slices += 1\n",
    "                else:\n",
    "                    correct_phase = False\n",
    "        if correct_phase:\n",
    "            correct_phases += 1\n",
    "\n",
    "    slice_accuracy = correct_slices / total_slices\n",
    "    phase_accuracy = correct_phases / total_phases\n",
    "\n",
    "    return slice_accuracy, phase_accuracy, total_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Validate results\n",
    "y_rnn = np.ndarray((0, 25, 5))\n",
    "for _, labels in tqdm(rnn_testgen):\n",
    "    y_rnn = np.concatenate([y_rnn, labels])\n",
    "get_accuracy(rnn_preds, y_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_result = evaluate_predictions(cnn_predictions)\n",
    "cnn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_result = evaluate_predictions(rnn_predictions)\n",
    "rnn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_key = \"initial_rnn\"\n",
    "os.makedirs(get_result_dir(result_key), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in rnn_predictions.items():\n",
    "    scores = value[\"scores\"]\n",
    "    for k, v in scores.items():\n",
    "        scores[k] = str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(get_history_path(result_key), \"w\") as f:\n",
    "    json.dump(rnn_history.history, f)\n",
    "with open(get_predictions_path(result_key), \"w\") as f:\n",
    "    json.dump(rnn_predictions, f)\n",
    "with open(get_result_path(result_key), \"w\") as f:\n",
    "    json.dump(rnn_result, f)\n",
    "rnn_model.save_weights(get_model_weights_path(result_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_key = \"initial_cnn\"\n",
    "os.makedirs(get_result_dir(result_key), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(get_history_path(result_key), \"w\") as f:\n",
    "    json.dump(cnn_history.history, f)\n",
    "with open(get_predictions_path(result_key), \"w\") as f:\n",
    "    json.dump(cnn_predictions, f)\n",
    "with open(get_result_path(result_key), \"w\") as f:\n",
    "    json.dump(cnn_result, f)\n",
    "cnn_model.save_weights(get_model_weights_path(result_key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
