{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, GlobalAveragePooling2D, LSTM, TimeDistributed, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_INDEX = {\n",
    "    'ap': 0,\n",
    "    'bs': 1,\n",
    "    'mid': 2,\n",
    "    'oap': 3,\n",
    "    'obs': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_app = tf.keras.applications.mobilenet\n",
    "keras_model = tf.keras.applications.mobilenet.MobileNet\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=keras_app.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data: Data, datasets=None, batch_size=32, target_size=(224, 224), slices_per_sample=25, shuffle=True, image_data_generator=None):\n",
    "        self.data = data\n",
    "        self.datasets = datasets\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size=  target_size\n",
    "        self.slices_per_sample = slices_per_sample\n",
    "        self.shuffle = shuffle\n",
    "        self.datagen = image_data_generator\n",
    "        \n",
    "        self.n_classes = 5\n",
    "        self.label_indices = { 'ap': 0,\n",
    "                            'bs': 1,\n",
    "                            'mid': 2,\n",
    "                            'oap': 3,\n",
    "                            'obs': 4,\n",
    "                           }\n",
    "\n",
    "        self.samples = dict()\n",
    "        self.max_slices = 0\n",
    "        \n",
    "        if datasets is None:\n",
    "            datasets = list(data.data.keys())\n",
    "        if isinstance(datasets, str):\n",
    "            datasets = [datasets]\n",
    "        \n",
    "        # All plural variables are dicts\n",
    "        for dataset in datasets:\n",
    "            for patient, slices in data.data[dataset].items():\n",
    "                for s, images in slices.items():\n",
    "                    key = \"{dataset}_{patient}_{slice}\".format(dataset=dataset, patient=patient, slice=s)\n",
    "                    self.samples[key] = images\n",
    "                    if len(images) > self.max_slices:\n",
    "                        self.max_slices = len(images)\n",
    "        \n",
    "        if slices_per_sample < self.max_slices:\n",
    "            raise ValueError(\"There are some samples that contain more than {} slices ({})\".format(\n",
    "                slices_per_sample, self.max_slices))\n",
    "        \n",
    "        unlabeled = []\n",
    "        self.images_by_label = [0] * len(self.label_indices)\n",
    "        for slices in self.samples.values():\n",
    "            for s in slices.values():\n",
    "                label = self.data.labels.get(s, None)\n",
    "                if label is None:\n",
    "                    unlabeled.append(s)\n",
    "                else:\n",
    "                    index = self.label_indices[label]\n",
    "                    self.images_by_label[index] += 1\n",
    "        if unlabeled:\n",
    "            raise ValueError(\"{} unlabeled slice(s): {}...\".format(len(unlabeled), str(unlabeled)[:200]))\n",
    "        \n",
    "        self.n_batches = math.ceil(len(self.samples) / batch_size)\n",
    "        \n",
    "        self._refresh_sample_keys()\n",
    "    \n",
    "    def _refresh_sample_keys(self):\n",
    "        self.sample_keys = sorted(list(self.samples.keys()))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.sample_keys)\n",
    "        \n",
    "    def _get_sample_key_batch(self, index):\n",
    "        return self.sample_keys[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "    def _load_and_preprocess_image(self, path, standardize=False):\n",
    "        img = load_img(path, color_mode=\"grayscale\", target_size=(224, 224))\n",
    "        x = img_to_array(img, data_format=\"channels_last\")\n",
    "        params = datagen.get_random_transform(x.shape)\n",
    "        x = x / 255\n",
    "        x = datagen.apply_transform(x, params)\n",
    "        x = np.concatenate([x, x, x], axis=2)\n",
    "        if standardize:\n",
    "            x = datagen.standardize(x)\n",
    "        return x\n",
    "    \n",
    "    def get_class_weight(self):\n",
    "        counts = np.array(self.images_by_label)\n",
    "        weights = counts.sum() / counts / len(counts)\n",
    "        weights = { i: weight for i, weight in enumerate(weights.tolist())}\n",
    "        return weights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get `index`th batch\n",
    "        \"\"\"\n",
    "        keys = self._get_sample_key_batch(index)\n",
    "        batch_size = len(keys)\n",
    "        x = np.zeros((batch_size, self.slices_per_sample) + self.target_size + (3,))\n",
    "        y = np.zeros((batch_size, self.slices_per_sample) + (self.n_classes,))\n",
    "        for i, key in enumerate(keys):\n",
    "            items = sorted(list(self.samples[key].items()))\n",
    "            for j, (slice_index, sid) in enumerate(items):\n",
    "                path = self.data.paths[sid]\n",
    "                image = self._load_and_preprocess_image(path, standardize=True)\n",
    "                x[i][j] = image\n",
    "                label = self.data.labels[sid]\n",
    "                label_index = self.label_indices[label]\n",
    "                y[i][j][label_index] = 1\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._refresh_sample_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = keras_model(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3))\n",
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(TimeDistributed(backbone))\n",
    "rnn_model.add(LSTM(512, input_shape=(25, 2048), return_sequences=True))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "rnn_model.add(LSTM(512, input_shape=(25, 2048), return_sequences=True))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "rnn_model.add(TimeDistributed(Dense(5, activation=\"softmax\")))\n",
    "\n",
    "rnn_model.layers[0].trainable = False\n",
    "rnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Solve class imbalance using `sample_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "487/487 [==============================] - 211s 432ms/step - loss: 0.1699 - accuracy: 0.6487\n",
      "Epoch 2/300\n",
      "487/487 [==============================] - 210s 431ms/step - loss: 0.1682 - accuracy: 0.5745\n",
      "Epoch 3/300\n",
      "487/487 [==============================] - 209s 428ms/step - loss: 0.1651 - accuracy: 0.5834\n",
      "Epoch 4/300\n",
      "407/487 [========================>.....] - ETA: 34s - loss: 0.1672 - accuracy: 0.5700"
     ]
    }
   ],
   "source": [
    "sequence = SliceDataGenerator(data, \"KAG\", batch_size=4)\n",
    "rnn_history = rnn_model.fit(sequence, epochs=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
