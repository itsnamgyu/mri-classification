{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, GlobalAveragePooling2D, LSTM, TimeDistributed, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_INDEX = {\n",
    "    'ap': 0,\n",
    "    'bs': 1,\n",
    "    'mid': 2,\n",
    "    'oap': 3,\n",
    "    'obs': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_app = tf.keras.applications.mobilenet\n",
    "keras_model = tf.keras.applications.mobilenet.MobileNet\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=keras_app.preprocess_input)\n",
    "datagen = ImageDataGenerator(preprocessing_function=keras_app.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data: Data, datasets=None, batch_size=32, target_size=(224, 224), \n",
    "                 slices_per_sample=25, shuffle=True, image_data_generator=None):\n",
    "        self.data = data\n",
    "        self.datasets = datasets\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size=  target_size\n",
    "        self.slices_per_sample = slices_per_sample\n",
    "        self.shuffle = shuffle\n",
    "        self.datagen = image_data_generator\n",
    "        \n",
    "        self.n_classes = 5\n",
    "        self.label_indices = LABEL_INDEX\n",
    "\n",
    "        self.samples = dict()\n",
    "        self.max_slices = 1\n",
    "        \n",
    "        if datasets is None:\n",
    "            datasets = list(data.data.keys())\n",
    "        if isinstance(datasets, str):\n",
    "            datasets = [datasets]\n",
    "        \n",
    "        # All plural variables are dicts\n",
    "        for dataset in datasets:\n",
    "            for patient, phases in data.data[dataset].items():\n",
    "                for phase, slices in phases.items():\n",
    "                    key = \"{dataset}_{patient:06d}_{slice:02d}\".format(dataset=dataset, patient=patient, slice=phase)\n",
    "                    self.samples[key] = slices\n",
    "                    if len(slices) > self.max_slices:\n",
    "                        self.max_slices = len(slices)\n",
    "        \n",
    "        if slices_per_sample < self.max_slices:\n",
    "            raise ValueError(\"There are some samples that contain more than {} slices ({})\".format(\n",
    "                slices_per_sample, self.max_slices))\n",
    "        \n",
    "        unlabeled = []\n",
    "        self.images_by_label = [0] * len(self.label_indices)\n",
    "        for phases in self.samples.values():\n",
    "            for phase in phases.values():\n",
    "                label = self.data.labels.get(phase, None)\n",
    "                if label is None:\n",
    "                    unlabeled.append(phase)\n",
    "                else:\n",
    "                    index = self.label_indices[label]\n",
    "                    self.images_by_label[index] += 1\n",
    "        if unlabeled:\n",
    "            raise ValueError(\"{} unlabeled slice(s): {}...\".format(len(unlabeled), str(unlabeled)[:200]))\n",
    "        \n",
    "        self.n_batches = math.ceil(len(self.samples) / batch_size)\n",
    "        \n",
    "        self._refresh_sample_keys()\n",
    "    \n",
    "    def _refresh_sample_keys(self):\n",
    "        self.sample_keys = sorted(list(self.samples.keys()))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.sample_keys)\n",
    "        \n",
    "    def _get_sample_key_batch(self, index):\n",
    "        return self.sample_keys[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "    def _load_and_preprocess_image(self, path, standardize=False):\n",
    "        img = Image.open(path)\n",
    "        img = img.resize(self.target_size, Image.NEAREST)\n",
    "        #img = load_img(path, color_mode=\"rgb\", target_size=self.target_size)\n",
    "        x = img_to_array(img, data_format=\"channels_last\")\n",
    "        params = datagen.get_random_transform(x.shape)\n",
    "        x = x / 65536 * 255\n",
    "        x = datagen.apply_transform(x, params)\n",
    "        if standardize:\n",
    "            x = datagen.standardize(x)\n",
    "        return x\n",
    "    \n",
    "    def get_class_weight(self):\n",
    "        counts = np.array(self.images_by_label)\n",
    "        weights = counts.sum() / counts / len(counts)\n",
    "        weights = { i: weight for i, weight in enumerate(weights.tolist())}\n",
    "        return weights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get `index`th batch\n",
    "        \"\"\"\n",
    "        keys = self._get_sample_key_batch(index)\n",
    "        batch_size = len(keys)\n",
    "        x = np.zeros((batch_size, self.slices_per_sample) + self.target_size + (3,))\n",
    "        y = np.zeros((batch_size, self.slices_per_sample) + (self.n_classes,))\n",
    "        for i, key in enumerate(keys):\n",
    "            items = sorted(list(self.samples[key].items()))\n",
    "            for j, (slice_index, sid) in enumerate(items):\n",
    "                path = self.data.paths[sid]\n",
    "                image = self._load_and_preprocess_image(path, standardize=True)\n",
    "                x[i][j] = image\n",
    "                label = self.data.labels[sid]\n",
    "                label_index = self.label_indices[label]\n",
    "                y[i][j][label_index] = 1\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._refresh_sample_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data: Data, datasets=None, batch_size=32,\n",
    "                 target_size=(224, 224), shuffle=True, image_data_generator=None):\n",
    "        self.data = data\n",
    "        self.datasets = datasets\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size=  target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.datagen = image_data_generator\n",
    "        \n",
    "        self.n_classes = 5\n",
    "        self.label_indices = LABEL_INDEX\n",
    "\n",
    "        self.slices = list()\n",
    "\n",
    "        if datasets is None:\n",
    "            datasets = list(data.data.keys())\n",
    "        if isinstance(datasets, str):\n",
    "            datasets = [datasets]\n",
    "        \n",
    "        # All plural variables are dicts\n",
    "        for dataset in datasets:\n",
    "            for patient, phases in data.data[dataset].items():\n",
    "                for phase, slices in phases.items():\n",
    "                    ordered = sorted(list(slices.items()))\n",
    "                    ordered_slices = [item[1] for item in ordered]\n",
    "                    self.slices.extend(ordered_slices)\n",
    "        self.slices.sort()\n",
    "\n",
    "        unlabeled = []\n",
    "        self.images_by_label = [0] * len(self.label_indices)\n",
    "        for slice in self.slices:\n",
    "            label = self.data.labels.get(slice, None)\n",
    "            if label is None:\n",
    "                unlabeled.append(slice)\n",
    "            else:\n",
    "                index = self.label_indices[label]\n",
    "                self.images_by_label[index] += 1\n",
    "        if unlabeled:\n",
    "            raise ValueError(\"{} unlabeled slice(s): {}...\".format(len(unlabeled), str(unlabeled)[:200]))\n",
    "        \n",
    "        self.n_batches = math.ceil(len(self.slices) / batch_size)\n",
    "        self._refresh_slice_order()\n",
    "    \n",
    "    def _refresh_slice_order(self):\n",
    "        self.slices = sorted(list(self.slices))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slices)\n",
    "        \n",
    "    def _get_slice_batch(self, index):\n",
    "        return self.slices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "    def _load_and_preprocess_image(self, path, standardize=False):\n",
    "        img = Image.open(path)\n",
    "        img = img.resize(self.target_size, Image.NEAREST)\n",
    "        #img = load_img(path, color_mode=\"rgb\", target_size=self.target_size)\n",
    "        x = img_to_array(img, data_format=\"channels_last\")\n",
    "        params = datagen.get_random_transform(x.shape)\n",
    "        x = x / 65536 * 255\n",
    "        x = datagen.apply_transform(x, params)\n",
    "        if standardize:\n",
    "            x = datagen.standardize(x)\n",
    "        return x\n",
    "    \n",
    "    def get_class_weight(self):\n",
    "        counts = np.array(self.images_by_label)\n",
    "        weights = counts.sum() / counts / len(counts)\n",
    "        weights = { i: weight for i, weight in enumerate(weights.tolist())}\n",
    "        return weights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get `index`th batch\n",
    "        \"\"\"\n",
    "        slices = self._get_slice_batch(index)\n",
    "        batch_size = len(slices)\n",
    "        x = np.zeros((batch_size, ) + self.target_size + (3,))\n",
    "        y = np.zeros((batch_size, ) + (self.n_classes,))\n",
    "        for i, sid in enumerate(slices):\n",
    "            path = self.data.paths[sid]\n",
    "            image = self._load_and_preprocess_image(path, standardize=True)\n",
    "            x[i] = image\n",
    "            label = self.data.labels[sid]\n",
    "            label_index = self.label_indices[label]\n",
    "            y[i][label_index] = 1\n",
    "\n",
    "        assert(y.sum() == len(slices))\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._refresh_slice_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlicewiseAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='slicewise_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total_slices = self.add_weight(name='ts', initializer='zeros')\n",
    "        self.correct_slices = self.add_weight(name='cs', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        total = tf.cast(tf.reduce_sum(y_true), tf.float32)  # one-hot\n",
    "        y_valid = tf.cast(tf.reduce_sum(y_true, axis=2), tf.bool)\n",
    "        \n",
    "        y_true = tf.argmax(y_true, axis=2)\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        correct = (y_true == y_pred) & y_valid\n",
    "        correct = tf.reduce_sum(tf.cast(correct, tf.float32))\n",
    "        \n",
    "        self.total_slices.assign_add(total)\n",
    "        self.correct_slices.assign_add(correct)\n",
    "\n",
    "    def result(self):\n",
    "        return self.correct_slices / self.total_slices\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.total_slices.assign(0)\n",
    "        self.correct_slices.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = SlicewiseAccuracy()\n",
    "acc.update_state(np.array([[[1, 0], [0, 0]]]), np.array([[[1, 0], [0, 1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_gen = PhaseDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_gen = SliceDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.isclose(slice_gen[0][0][0].min(), -1, rtol=1.0e-4))\n",
    "assert(np.isclose(slice_gen[0][0][0].max(), 1, rtol=1.0e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.isclose(phase_gen[0][0][0].min(), -1, rtol=1.0e-4))\n",
    "assert(np.isclose(phase_gen[0][0][0].max(), 1, rtol=1.0e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_app = tf.keras.applications.mobilenet\n",
    "keras_model = tf.keras.applications.mobilenet.MobileNet\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=keras_app.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = keras_model(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3))\n",
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(backbone)\n",
    "cnn_model.add(Dense(256, activation=\"relu\"))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "cnn_model.layers[0].trainable = False\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_model.fit(slice_gen, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(TimeDistributed(backbone))\n",
    "rnn_model.add(LSTM(256, input_shape=(25, 2048), return_sequences=True))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "#rnn_model.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "#rnn_model.add(TimeDistributed(Dropout(0.5)))\n",
    "rnn_model.add(TimeDistributed(Dense(5, activation=\"softmax\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_model.layers[0].trainable = False\n",
    "rnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[SlicewiseAccuracy(), \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_model.fit(phase_gen, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = PhaseDataGenerator(data, \"KAG\", target_size=(224, 224), batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rnn_model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = None\n",
    "for _, batch in test_gen:\n",
    "    if labels is None:\n",
    "        labels = batch\n",
    "    else:\n",
    "        labels = np.concatenate([labels, batch])\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels):\n",
    "    total_slices = 0\n",
    "    total_phases = 0\n",
    "    correct_slices = 0\n",
    "    correct_phases = 0\n",
    "\n",
    "    for phase, slices in enumerate(preds):\n",
    "        total_phases += 1\n",
    "        correct_phase = True\n",
    "        for slice, pred in enumerate(slices):\n",
    "            label = labels[phase][slice]\n",
    "            if label.sum() == 0:\n",
    "                pass\n",
    "            else:\n",
    "                total_slices += 1\n",
    "                if label.argmax() == pred.argmax():\n",
    "                    correct_slices += 1\n",
    "                else:\n",
    "                    correct_phase = False\n",
    "        if correct_phase:\n",
    "            correct_phases += 1\n",
    "\n",
    "    slice_accuracy = correct_slices / total_slices\n",
    "    phase_accuracy = correct_phases / total_phases\n",
    "\n",
    "    return slice_accuracy, phase_accuracy, total_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_accuracy, phase_accuracy, ts = get_accuracy(preds, labels)\n",
    "print(\"Slice accuracy:\", slice_accuracy)\n",
    "print(\"Phase accuracy:\", phase_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts / (preds.shape[0] * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
